{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV 2021 HW2-3 Colorizing Russian Empire\n",
    "\n",
    "## Introduction\n",
    "- In this section, we need to write a script that **automatically** produce color images from the digitalized [Prokudin- Gorskii glass plate images](http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15463-s10/www/proj1/www/abarnat/images/standard/)\n",
    "- We are asked to assume that **only x, y translation are needed** to align different color channels of the images, which turns out to be insufficient for aligning large images (discussed at last part).\n",
    "- We implement a two-stage alignment process based on [Canny edge detector](https://en.wikipedia.org/wiki/Canny_edge_detector), our method is highly efficiant because we only correlate between binary edge images.\n",
    "- For large images of size (MxN), edge detecting and correlating becomes computationaly expansive. We avoid this problem by first resizeing the input images to (300x300), we then find  x, y translation for aligning these smaller images. Finally, to align the large images of original size, we scaled the previous translation by the resizing ratio\n",
    " \n",
    " $$X_{original} = {x_{resized} \\times \\lfloor{ M \\over 300 }\\rfloor} $$\n",
    " $$Y_{original} = {y_{resized} \\times \\lfloor{ N \\over 300 }\\rfloor} $$\n",
    " \n",
    "- While the resizing mechanism speeds things up, it fails to align the original images accurately due to the rounding effect of scaling the translation. To solve this, we crop a small region of the previous aligned image, and **do the alignment process on the small region again**. The resulting $X_{correction} , Y_{correction}$ translation of the small region is then applied to the whole image to yeild result of higher quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "- `image_file` input image location\n",
    "- `plot_log=True` plot intermediate result\n",
    "- `save_intermediate` save real-size image after first alignment\n",
    "- `save_final` save real-size image after secong alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = 'hw2_data/task3_colorizing/melons.tif'\n",
    "plot_log = False\n",
    "save_intermediate = True\n",
    "save_final = True\n",
    "\n",
    "#---------------------------\n",
    "filename, filetype = image_file.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 \n",
    "- Read input image channels from file. \n",
    "    \n",
    "    `r,g,b` variables store the real-size (`M`x`N`) image channels.\n",
    "- Resize each image to (300x300).\n",
    "\n",
    "    `rr,gg,bb` variables store the resized image channels.\n",
    "- Apply *Canny edge dection* on each channel.\n",
    "\n",
    "    `rre, gge, bbe` variables store the edge of resized image channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "img = cv2.imread(image_file,0)\n",
    "\n",
    "M,N = img.shape\n",
    "r,g,b = img[0:M//3,:], img[M//3:M//3*2,:] , img[M//3*2:M//3*3,:]\n",
    "\n",
    "rr = cv2.resize(r,(300,300))\n",
    "gg = cv2.resize(g,(300,300))\n",
    "bb = cv2.resize(b,(300,300))\n",
    "\n",
    "rre = cv2.Canny(rr,100,150)\n",
    "gge = cv2.Canny(gg,100,150)\n",
    "bbe = cv2.Canny(bb,100,150)\n",
    "\n",
    "#plot the result\n",
    "if plot_log:\n",
    "    f = plt.figure(figsize=(14,21))\n",
    "    plt.subplot(321),plt.imshow(rr,cmap = 'gray'),plt.title('Resized R'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(322),plt.imshow(rre,cmap = 'gray'),plt.title('Edged R'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(323),plt.imshow(gg,cmap = 'gray'),plt.title('Resized G'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(324),plt.imshow(gge,cmap = 'gray'),plt.title('Edged G'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(325),plt.imshow(bb,cmap = 'gray'),plt.title('Resized B'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(326),plt.imshow(bbe,cmap = 'gray'),plt.title('Edged B'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 (align small image)\n",
    "### Shift and correlate the Canny edge images to find the aligning offset. \n",
    "\n",
    "-   This process is implemented in **`find_offset`** function, which correlates 2 binary edge images, by summation after elemenwise `bitwise_and`.\n",
    "\n",
    "    \n",
    "    **Function input:**\n",
    "    \n",
    "    > 1. `e1`: image1\n",
    "    > 2. `e2`: image2\n",
    "    > 3. `x_range`: translation search range (from `-x_range` to `x_range`) in x direction\n",
    "    > 4. `y_range`: translation search range (from `-y_range` to `y_range`) in y direction\n",
    "    \n",
    "    **Funciton output:**\n",
    "    > `(x,y)` : the best translation offset in both axis\n",
    "The \n",
    "\n",
    "### Apply the offset to the resized-image and edge-images to see the aligning effect.\n",
    "    \n",
    "    \n",
    "-   This process in implemented in **align** function.\n",
    "\n",
    "       \n",
    "    **Function input:**   \n",
    "    > 1. `img1`: image of channel 1\n",
    "    > 2. `img2`: image of channel 2\n",
    "    > 3. `img3`: image of channel 3\n",
    "    > 4. `offset_21`: translation offset between img2 and img1\n",
    "    > 5. `offset_23`: translation offset between img2 and img3\n",
    "    \n",
    "    **Funciton output:**\n",
    "    >  `result ` resulting image with 3 channels  \n",
    "    \n",
    "Note that both `find_offset` and `align` can be used on images of any size, they will be reused several times in latter stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_width\n",
    "c = 20\n",
    "\n",
    "# find the shifting offset given two binary edge image  \n",
    "def find_offset(e1,e2,x_range, y_range):\n",
    "    \"align the two binary images\"\n",
    "    assert e1.shape == e2.shape\n",
    "    M,N = e2.shape\n",
    "    best_score = 0\n",
    "    best_offset = None\n",
    "    patch1 = e1[x_range:-x_range,y_range:-y_range]\n",
    "    for i in range(-x_range,x_range):\n",
    "        for j in range(-y_range,y_range):\n",
    "            patch2 = e2[i+x_range:i-x_range,j+y_range:j-y_range]\n",
    "            current_score = np.sum( np.bitwise_and(patch1, patch2) )\n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_offset = (i,j)\n",
    "    return best_offset \n",
    "\n",
    "# align 3 image channels given shifting offset\n",
    "def align(img1,img2,img3, offset21, offset23):\n",
    "    x21,y21 = offset21\n",
    "    x23,y23 = offset23\n",
    "    c =  max(np.abs([x21, x23, y21, y23]))+1\n",
    "    result = np.stack([img1[c+x21:-c+x21,c+y21:-c+y21],\n",
    "                       img2[c:-c,c:-c],\n",
    "                       img3[c+x23:-c+x23,c+y23:-c+y23]],axis=2)\n",
    "    return result\n",
    "\n",
    "gr = find_offset(gge[c:-c,c:-c]//255,rre[c:-c,c:-c]//255,30,30)\n",
    "gb = find_offset(gge[c:-c,c:-c]//255,bbe[c:-c,c:-c]//255,30,30)\n",
    "aligned_edge = align(rre,gge,bbe,gr,gb)\n",
    "\n",
    "if plot_log:\n",
    "    aligned = align(rr,gg,bb,gr,gb)\n",
    "\n",
    "    f = plt.figure(figsize=(15,30))\n",
    "    plt.subplot(311),plt.imshow(np.stack([rr,gg,bb],axis=2)[c:-c,c:-c]),plt.title('Original')#, plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(312),plt.imshow(aligned_edge),plt.title('Edge Aligned')#, plt.xticks([]), plt.yticks([])\n",
    "    #plt.subplot(313),plt.imshow(cv2.normalize(aligned,aligned,255,0,norm_type=cv2.NORM_MINMAX)),plt.title('Aligned'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(313),plt.imshow(aligned),plt.title('Small Image Aligned')#, plt.xticks([]), plt.yticks([])\n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2  ( scale the offset and align real-size image)\n",
    "- Scale the translating offsets found in the previous step and apply the result to real-size images\n",
    "\n",
    "> `gr_real` is the scaled offset from `gr`\n",
    "\n",
    "> `gb_real` is the scaled offset from `gb`\n",
    "\n",
    "- Save the result if specified.\n",
    "\n",
    "- If we plot the **Zoomed Detail** of the real-size aligned images, we might see small defect cause by the scaling process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the offset\n",
    "gr_real = (int(np.round((M//3)/300 * gr[0])), int(np.round(N/300 * gr[1])))\n",
    "gb_real = (int(np.round((M//3)/300 * gb[0])), int(np.round(N/300 * gb[1])))\n",
    "# apply offset to real size images\n",
    "aligned_real = align(r,g,b,gr_real,gb_real)\n",
    "\n",
    "#save file\n",
    "if save_intermediate:\n",
    "    cv2.imwrite(filename+'_intermediate'+'.'+filetype,aligned_real)\n",
    "\n",
    "if plot_log:\n",
    "    plt.figure(figsize=(10,15))\n",
    "    ax = plt.subplot(211)\n",
    "    ax.imshow(aligned_real)\n",
    "    ax.set_title('Real-size image')\n",
    "    #x_rand,y_rand=np.random.randint(low=M//30*2,high=M//3-M//30*2), np.random.randint(low=N//10*2,high=N-N//10*2)\n",
    "    x_rand,y_rand = M//6,N//2\n",
    "    rect = patches.Rectangle((y_rand,x_rand),M//60,N//20, linewidth=3, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax = plt.subplot(212)\n",
    "    ax.set_title('Zoomed Detail')\n",
    "\n",
    "    print(x_rand,y_rand)\n",
    "    plt.imshow(aligned_real[x_rand:x_rand+ M//30,y_rand:y_rand+ N//10])\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 (Choose edge-rich rect region for error correction)\n",
    "- For small-sized images we already get satisfying result, this and the following steps are optional.\n",
    "- For large image, we first find a small rectangular region that contains resonable amount of edges \n",
    "\n",
    "    This process is implemented in `find_edge_region` function, \n",
    "    where we seperate the small-edge images in to 10x10 tiny rect regions,\n",
    "    and then iterate through each region, find the one that contains the most **\"edge aligning information\"**  \n",
    "    > The metric used here to evaluate the amount of \"aligning information\" is as follows: \n",
    "    > \n",
    "    $$ Edge\\_Score = \\Sigma_{all\\_pixels}  [ \\mathtt{bitwise\\_and (re, ge, be)} + \\mathtt{re} + \\mathtt{ge} + \\mathtt{be} ]  $$\n",
    "    >\n",
    "    > where `re`, `ge`, `be` are the Canny Edge of each channel of aligned small image\n",
    "    \n",
    "    > `bitwise_and` find those pixel where edges are presented in all 3 channel (great alignment)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busy region: (6, 7)\n"
     ]
    }
   ],
   "source": [
    "#Further Enhencement\n",
    "\n",
    "# find complex location in small image\n",
    "def find_edge_region(re,ge,be):\n",
    "    \"\"\" Given binary canny edges as input, output the coordinate of the top-left corner of a busy region\n",
    "        The coordinate is normalized to the range (0,10)x(0,10)\n",
    "    \"\"\"\n",
    "    assert re.shape == ge.shape and re.shape == be.shape\n",
    "    m,n = re.shape\n",
    "    s = m//10\n",
    "    best_score = 0\n",
    "    best_region = None\n",
    "    for i in range(2,8):\n",
    "        for j in range(2,8):\n",
    "            re_patch = re[i*s:(i+1)*s,j*s:(j+1)*s]\n",
    "            ge_patch = ge[i*s:(i+1)*s,j*s:(j+1)*s]\n",
    "            be_patch = be[i*s:(i+1)*s,j*s:(j+1)*s]\n",
    "            matching_score =  np.sum(np.bitwise_and(np.bitwise_and(re_patch,ge_patch),be_patch))\n",
    "            edge_amount = np.sum(re_patch) + np.sum(ge_patch) + np.sum(be_patch)\n",
    "            current_score = matching_score + edge_amount\n",
    "            if current_score > best_score:\n",
    "                best_score = current_score\n",
    "                best_region = (i,j)\n",
    "    return best_region\n",
    "\n",
    "er = find_edge_region(*[aligned_edge[:,:,i]//255 for i in range(3)])\n",
    "print(f'busy region: {er}')\n",
    "\n",
    "if plot_log: \n",
    "    fig,ax = plt.subplots(1,3,figsize=(20,6))\n",
    "    ax[0].imshow(aligned_edge)\n",
    "    ax[0].set_title('Choose Busy region')\n",
    "    x,y = aligned_edge.shape[0]//10, aligned_edge.shape[1]//10\n",
    "    X,Y = M//30, N//10\n",
    "    rect = patches.Rectangle((x*er[1],y*er[0]),x,y, linewidth=5, edgecolor='w', facecolor='none')\n",
    "    ax[0].add_patch(rect)\n",
    "    ax[1].set_title('Edge zoomed')\n",
    "    ax[1].imshow(aligned_edge[x*er[0]:x*er[0]+x, y*er[1]:y*er[1]+y])\n",
    "    ax[2].set_title('Chosen Region in real size')\n",
    "    ax[2].imshow(aligned_real[X*er[0]:X*er[0]+X, Y*er[1]:Y*er[1]+Y])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 (Alignment for the 2'nd time)\n",
    "- After finding a region, we repeat the process of `find_offset` on that small region of real size image,\n",
    "    and then apply the $X_{correction}$ , $Y_{correction}$ offsets to the whole real size image.\n",
    "- In the code below, `re`, `ge`, `be` store the Canny edges of the croped rectangular edge-rich region that we chose in the previous step\n",
    "\n",
    "   `gr2` and `gb2` stors the offset information for the second alignment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e5b46cd158da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# crop the edge region from aligned real size image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0medge_region\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maligned_real\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# find edge using Canny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_region\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# crop the edge region from aligned real size image \n",
    "edge_region = aligned_real[ X*er[0]:X*er[0] +X , Y*er[1]:Y*er[1]+Y, : ]\n",
    "# find edge using Canny\n",
    "re = cv2.Canny(edge_region[:,:,0],100,150)\n",
    "ge = cv2.Canny(edge_region[:,:,1],100,150)\n",
    "be = cv2.Canny(edge_region[:,:,2],100,150)\n",
    "\n",
    "# find offset for the second alignment process\n",
    "gr2 = find_offset(ge//255,re//255,X//10,Y//10)\n",
    "gb2 = find_offset(ge//255,be//255,X//10,Y//10)\n",
    "print(f'offset gr={gr2}, offset gb = {gb2}')\n",
    "\n",
    "# final result\n",
    "aligned_real2 = align(*[aligned_real[:,:,i] for i in range(3)],gr2,gb2)\n",
    "\n",
    "if save_final:\n",
    "    cv2.imwrite(filename+'_final.'+filetype,aligned_real2)\n",
    "\n",
    "if plot_log:\n",
    "    aligned_edge2 = align(re,ge,be,gr2,gb2)\n",
    "    f = plt.figure(figsize=(14,14))\n",
    "    plt.subplot(221),plt.imshow(re,cmap = 'gray'),plt.title('Edge Region R'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(222),plt.imshow(ge,cmap = 'gray'),plt.title('Edge Region G'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(223),plt.imshow(be,cmap = 'gray'),plt.title('Edge Region B'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(224),plt.imshow(aligned_edge2),plt.title('Edge Aligned'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Comparason\n",
    "\n",
    "- If we **Zoom In** the real-size image, we can see that the result after Second Alignment is much better in the Target Region (ie, edge-rich rect we chose).\n",
    "- However, even if we align perfectly in the chosen small region, other region may still encounter serious shifting phenomenon, this implys that the channels in the original image are **not only shifted, but also distorted**, hence it is impossible to get perfect alignment in all the region if we only consider translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_log: \n",
    "    f,ax = plt.subplots(2,2,figsize=(20,20))\n",
    "    ax[0][0].imshow(aligned_real[x_rand:x_rand+ X,y_rand:y_rand+ Y])\n",
    "    ax[0][0].set_title('Single Alignment (Sample)')\n",
    "    ax[0][1].imshow(aligned_real2[x_rand:x_rand+ X,y_rand:y_rand+ Y])\n",
    "    ax[0][1].set_title('Double Alignment (Sample)')\n",
    "    ax[1][0].imshow(aligned_real[X*er[0]:X*er[0]+X, Y*er[1]:Y*er[1]+Y])\n",
    "    ax[1][0].set_title('Single Alignment (Target)')\n",
    "    ax[1][1].imshow(aligned_real2[X*er[0]:X*er[0]+X,Y*er[1]:Y*er[1]+Y])\n",
    "    ax[1][1].set_title('Double Alignment (Target)')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
